{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/hemang/.cache/huggingface/datasets/flaviagiammarino___parquet/flaviagiammarino--vqa-rad-d04980c9c3579419/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6705b664224fe8a604b47653413576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the VQA-RAD dataset\n",
    "dataset = load_dataset(\"flaviagiammarino/vqa-rad\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']  # Assuming there is a validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemang/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/hemang/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load and configure ResNet-50 for image feature extraction\n",
    "resnet50 = models.resnet50(pretrained=True).to(device)\n",
    "resnet50.eval()\n",
    "\n",
    "# Define image transformations\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def extract_image_features(image):\n",
    "    image = image_transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = resnet50(image)\n",
    "    return features.squeeze().cpu()\n",
    "\n",
    "# Load and configure RoBERTa for question feature extraction\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
    "roberta = AutoModel.from_pretrained(\"roberta-large\").to(device)\n",
    "roberta.eval()\n",
    "\n",
    "def extract_question_features(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = roberta(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Applying Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b402b0e28f2475ebb2b7c7ee88be2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemang/anaconda3/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def extract_and_store_features(dataset):\n",
    "    def extract_features(example):\n",
    "        image_features = extract_image_features(example['image'])\n",
    "        question_features = extract_question_features(example['question'])\n",
    "        return {\n",
    "            'image_features': image_features.tolist(),\n",
    "            'question_features': question_features.tolist(),\n",
    "            'label': example['answer']  # Assuming the label is in the 'answer' field\n",
    "        }\n",
    "    \n",
    "    # Apply the feature extraction\n",
    "    dataset = dataset.map(extract_features, batched=False)\n",
    "    return dataset\n",
    "\n",
    "# Apply extraction to both the train and validation datasets\n",
    "train_dataset = extract_and_store_features(train_dataset)\n",
    "val_dataset = extract_and_store_features(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Feature Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034eeab2f1ae4db0a26af5f192737d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=566x555 at 0x318EC0F70>, 'question': 'are regions of the brain infarcted?', 'answer': 'yes', 'fused_features': [-0.5906049013137817, 0.020100682973861694, -2.452608108520508, -2.477351188659668, -2.0391666889190674, 1.9935781955718994, -1.9074671268463135, -1.4941680431365967, -1.4936150312423706, -1.7339797019958496, -1.1249819993972778, -2.008788585662842, -3.0406320095062256, -1.2158317565917969, -3.1965487003326416, -1.630664587020874, -2.6300954818725586, -2.8184030055999756, -2.211179733276367, -1.7090799808502197, -3.6795639991760254, -3.256092071533203, -2.9643073081970215, -3.0194427967071533, -1.6830921173095703, 0.01633782684803009, 1.0731507539749146, 1.8693488836288452, 0.34705084562301636, 0.46981221437454224, -2.016859531402588, -1.747003197669983, -1.6568148136138916, -1.1453027725219727, 1.1254029273986816, 0.09883427619934082, -0.11811798810958862, -1.4167704582214355, 3.005192756652832, 0.21952728927135468, 0.7135702967643738, -0.8554497957229614, -0.602319598197937, 3.6011550426483154, -0.9083153009414673, -0.5280309319496155, 0.03182081878185272, 2.35774302482605, -1.0542235374450684, -2.179749011993408, -2.647038698196411, 0.29142236709594727, 0.47689884901046753, 0.47210007905960083, 1.108834981918335, -1.0084360837936401, -1.4839551448822021, -2.1130330562591553, -1.5339363813400269, 0.9640543460845947, 0.8473007678985596, -1.103306531906128, -1.2501269578933716, 0.701361358165741, -0.5554514527320862, 0.36214688420295715, 1.2551124095916748, -1.0057883262634277, 1.0667946338653564, 3.7084474563598633, -0.8139559030532837, 0.9306582808494568, -1.9137051105499268, 2.612229824066162, -2.4346938133239746, 1.458993673324585, 0.9564933776855469, -0.3247106373310089, 3.7594125270843506, 0.9580532908439636, -0.28190356492996216, -2.8516998291015625, -1.6960328817367554, -1.2039761543273926, -2.3933255672454834, -2.1394600868225098, -1.3329484462738037, -0.4137133061885834, -0.7381091713905334, -0.9413022994995117, -2.430563449859619, -2.5425760746002197, -2.117976188659668, -3.8594472408294678, -2.405388832092285, -3.9247989654541016, -2.1607797145843506, -4.261224746704102, -2.779172897338867, -1.8733863830566406, -0.06753659248352051, -0.5087202787399292, -1.5107998847961426, -1.1826006174087524, -3.404435634613037, -3.4108638763427734, -1.4727421998977661, 1.9920378923416138, 0.11588791012763977, 1.8348667621612549, -0.3024396300315857, 7.1310014724731445, 1.4418885707855225, 1.3585046529769897, -0.5753777623176575, -2.8513708114624023, 1.410926342010498, 3.9138078689575195, -1.8746529817581177, -2.7875208854675293, -2.2689309120178223, -2.9470601081848145, -2.1434390544891357, -3.7002477645874023, -2.768056631088257, -0.7634907960891724, 2.549043655395508, -1.134537935256958, -0.6943865418434143, -1.5091638565063477, -1.4498239755630493, -4.626591682434082, -1.3483858108520508, -3.6078217029571533, -2.8689165115356445, -3.1096556186676025, -2.830145835876465, -2.402254581451416, -3.4892282485961914, -4.261405944824219, -2.4951093196868896, -1.9151743650436401, -3.9660472869873047, -1.4762355089187622, -3.6554489135742188, -2.452971935272217, -3.735076427459717, -2.0560526847839355, -1.5966171026229858, -1.6098132133483887, -3.1704928874969482, -0.11684346944093704, -0.4611670672893524, -2.0167548656463623, -0.6446962952613831, -1.3255256414413452, -1.2162830829620361, -1.6250346899032593, -1.05378258228302, -1.9073724746704102, -2.229865312576294, -1.8673152923583984, -2.5397181510925293, -0.5337817668914795, -1.9127311706542969, -0.8037026524543762, -2.924896717071533, -1.93009614944458, -2.0433597564697266, -2.1938915252685547, -1.960329532623291, -2.2350029945373535, -1.3042092323303223, -0.6834180951118469, -2.112947463989258, -1.236458659172058, -1.954227328300476, -2.4334139823913574, -1.1944600343704224, -1.1272058486938477, -0.6175659894943237, -0.28617680072784424, -2.8227429389953613, 0.04629899561405182, -2.0699872970581055, -1.5969817638397217, -1.5154398679733276, -1.5863133668899536, -0.8314698338508606, -0.44560784101486206, 0.36554569005966187, -1.289590835571289, -1.9938855171203613, -3.9108104705810547, -1.5226922035217285, -0.22741243243217468, -2.575639247894287, -1.3072162866592407, -2.3360540866851807, -0.18758881092071533, -1.5255141258239746, -3.284196138381958, 0.18350310623645782, -0.13737091422080994, -2.569214344024658, -2.003139019012451, 0.15647506713867188, 1.079039454460144, -0.06891429424285889, -1.3425710201263428, -3.142258644104004, -3.095360040664673, -3.085937976837158, -2.3293306827545166, -1.1803088188171387, -0.8711395859718323, -0.08886837959289551, -1.876281499862671, -2.445324182510376, -0.3475532531738281, -0.4712276756763458, -1.1957001686096191, 0.4059801399707794, -1.1157299280166626, 0.33838725090026855, -1.0072026252746582, -1.4460561275482178, -0.953165590763092, -0.7179937362670898, -1.036145806312561, -3.678450345993042, 0.3393933176994324, -1.0960760116577148, -0.20929276943206787, -1.3665015697479248, -2.102301597595215, -1.1589350700378418, -2.5799691677093506, -1.512892246246338, -2.102194309234619, -1.6655839681625366, -0.15943564474582672, -1.1961426734924316, -0.04553517699241638, -2.286350727081299, -1.5765775442123413, -1.3386316299438477, -0.10122421383857727, -0.9819340705871582, -1.9351024627685547, -1.1523303985595703, -1.2063896656036377, -0.8801050186157227, -1.2261948585510254, 0.41670912504196167, -0.4742586016654968, -1.9189996719360352, -1.5026428699493408, -2.776111125946045, -1.9752962589263916, -0.9693132042884827, -3.694281816482544, -1.6423976421356201, -2.282759428024292, -2.2374765872955322, -2.2603816986083984, -1.9185073375701904, -2.6251330375671387, -1.8477200269699097, -1.8455839157104492, -0.30050185322761536, -0.9699280858039856, -2.112217426300049, 0.4370989203453064, -2.648947238922119, -1.5805127620697021, -2.331453323364258, -1.3511970043182373, -0.5110004544258118, -1.6458079814910889, -0.7466436624526978, -0.6083157062530518, -1.7494006156921387, -0.9869958162307739, -0.259285569190979, -0.2684137523174286, -1.0565396547317505, -2.9519381523132324, -1.4751019477844238, -1.9931275844573975, -2.8589203357696533, -1.3178950548171997, -1.2420220375061035, -1.9470677375793457, -2.8840255737304688, -3.761685848236084, -1.4248038530349731, -3.144132614135742, -1.146570086479187, -0.7682236433029175, -0.8540847897529602, -0.7407362461090088, 1.1389012336730957, -0.9066261053085327, 0.16927766799926758, -0.19485239684581757, 0.6678708791732788, -1.4049233198165894, -1.1829646825790405, -1.0516242980957031, 1.8393793106079102, 0.5319862961769104, -0.7665068507194519, 0.4456847608089447, 0.6746821999549866, -0.34772732853889465, -1.7541500329971313, -2.0581884384155273, 2.437359571456909, -0.031014978885650635, -0.44046157598495483, 0.01724758744239807, 2.4902937412261963, -0.6780246496200562, 1.4432487487792969, 1.1195780038833618, 3.7627739906311035, 0.17815354466438293, 3.3006410598754883, -0.9107874631881714, -0.9659864902496338, -1.0141735076904297, -1.5584344863891602, 1.3907864093780518, -1.5286332368850708, -0.19004619121551514, -2.632479667663574, -2.029374122619629, 1.21537184715271, -1.9575202465057373, -1.107456922531128, 0.7593481540679932, -1.2519325017929077, -3.0308380126953125, -3.314194440841675, 0.9036540985107422, -3.5371580123901367, -2.139110803604126, -1.5781116485595703, -1.8136310577392578, 0.7380220293998718, -1.9101719856262207, -1.3505885601043701, -0.7544366121292114, -1.4615364074707031, -2.344604969024658, 0.18542829155921936, -0.2589329481124878, -0.06164640188217163, 2.059565782546997, -2.126359701156616, -0.9429520964622498, -0.580068826675415, -1.2197747230529785, -2.599780797958374, -2.848905086517334, -3.4978108406066895, -3.175211191177368, -2.630143404006958, -2.9173474311828613, -1.6240483522415161, -2.0916104316711426, -4.403665065765381, -2.347822666168213, -2.8072502613067627, -3.185516834259033, -2.059757947921753, -0.6878342032432556, -2.6910171508789062, -3.284017562866211, -2.292487144470215, -3.244605779647827, -1.3158905506134033, -1.805117130279541, 0.2716410756111145, 0.26384180784225464, -0.5607868432998657, -3.030593156814575, -2.4475717544555664, -2.195831775665283, -1.0798453092575073, -2.1626646518707275, 0.6799531579017639, -2.442333936691284, -0.9938552379608154, -1.5126399993896484, -0.774529218673706, -0.4304244816303253, 0.050117164850234985, 1.4355846643447876, 0.41950637102127075, 2.0375800132751465, 0.6482650637626648, -3.0604159832000732, -3.4061665534973145, -0.8782649636268616, -1.2716609239578247, -2.5195980072021484, -0.7011508941650391, 7.099710464477539, -1.596387267112732, -0.1200646162033081, 0.5207622051239014, 1.5629034042358398, 0.5131329894065857, -0.36743712425231934, 0.7731362581253052, -1.7242003679275513, 2.7293710708618164, 3.132157325744629, 2.3078536987304688, 0.4571858048439026, 3.191051721572876, -0.8362904191017151, -1.7046793699264526, -2.4096100330352783, 3.243312120437622, 3.1075937747955322, -0.0990409404039383, 2.7600536346435547, -3.1863725185394287, -1.9161988496780396, 0.47123032808303833, 1.8876186609268188, 0.337841272354126, -1.950899362564087, -2.141310691833496, -1.5427277088165283, 2.8931190967559814, 0.41467005014419556, 1.3147934675216675, 0.2989410161972046, 0.8623997569084167, 3.1331870555877686, 0.014904052019119263, -1.0381255149841309, 3.625114917755127, 3.965147018432617, 1.9028311967849731, -2.8275649547576904, -3.190845489501953, 4.001852035522461, 3.2248499393463135, -0.5125747919082642, -2.991987466812134, 3.052464008331299, 2.155978202819824, 1.5172737836837769, -1.0519061088562012, 3.161766529083252, -1.4425685405731201, 1.4034526348114014, -0.1539926826953888, 2.2550835609436035, 4.931427001953125, 1.7830884456634521, -2.5599546432495117, -1.8949921131134033, -1.166236400604248, 2.271756887435913, 1.2432169914245605, 1.7366526126861572, -2.2774739265441895, 4.0783915519714355, 2.0578534603118896, 3.124296188354492, -1.7724425792694092, 2.0852737426757812, 1.6934080123901367, 2.398186445236206, -0.5542613863945007, 6.26226806640625, 4.6323676109313965, -0.7991977334022522, -4.370889663696289, 2.311039447784424, 0.2642628848552704, 1.2397814989089966, 2.444669485092163, -0.6519030332565308, 1.2116239070892334, 3.1528141498565674, 0.07518622279167175, -0.18615557253360748, 8.105059623718262, -1.5492862462997437, -0.6376883387565613, -0.929649829864502, -0.8894942402839661, 1.798025369644165, -1.6573336124420166, 0.6816902160644531, 0.8013080954551697, 0.9085201025009155, 2.414165496826172, 3.184767007827759, 2.742084264755249, 5.850957870483398, 2.0714943408966064, -1.877253532409668, -3.8124401569366455, -3.7589023113250732, 1.5932667255401611, 1.6182365417480469, 2.897934913635254, 0.08551064133644104, 0.7971423864364624, 0.8339262008666992, 1.3899602890014648, 0.47151967883110046, -2.1172120571136475, 1.2464724779129028, 0.5335483551025391, -1.1014518737792969, 1.2956748008728027, -1.6599434614181519, -0.6091314554214478, -0.18443971872329712, 2.2064576148986816, 0.6878670454025269, 2.794558048248291, 2.436225414276123, -2.1419754028320312, 2.6188535690307617, -0.24948006868362427, 1.1567811965942383, -3.141162157058716, -2.384202718734741, 0.23247331380844116, 1.157461404800415, -1.5069125890731812, 5.025882244110107, 2.6959919929504395, 2.3767566680908203, 2.401731014251709, 2.3381927013397217, 1.3162784576416016, -1.953129768371582, -1.079843521118164, 3.3059301376342773, 0.895820140838623, 6.226243019104004, 1.724769115447998, 0.09139090031385422, -2.8203883171081543, -1.039363145828247, 0.8408437371253967, -1.9045467376708984, 0.4221435785293579, -1.2695006132125854, -0.6093802452087402, 0.47477295994758606, -0.9464299082756042, 1.8258602619171143, -2.0369999408721924, 0.42556020617485046, 1.4628043174743652, 3.179718494415283, -0.8196597695350647, -1.168880820274353, 4.585010051727295, -0.8782590627670288, 1.0718306303024292, -2.5922746658325195, 2.8137385845184326, -2.045988082885742, -3.102185010910034, 8.794022560119629, -0.17222321033477783, -0.2319371998310089, -1.2639094591140747, -0.7886013984680176, -1.8590874671936035, 1.5836615562438965, 3.3640058040618896, 2.3709325790405273, 1.349975824356079, 4.325075149536133, -0.22993308305740356, 2.396786689758301, 1.7210662364959717, 2.092987060546875, 1.5510755777359009, 2.313429355621338, 0.771222710609436, -0.47221964597702026, 3.758633613586426, -0.04664130508899689, -1.2750346660614014, 2.2026991844177246, 4.130079746246338, 0.787306010723114, 0.12593242526054382, -2.8246095180511475, 2.3953099250793457, 4.619199752807617, 4.002870559692383, -0.12831975519657135, 2.8205630779266357, 0.796047031879425, 1.9275349378585815, 2.0566515922546387, -1.039342999458313, 0.9816705584526062, -1.6203086376190186, 2.0295839309692383, 1.7944930791854858, 1.3264449834823608, 0.9380373358726501, 1.5167248249053955, 0.6598370671272278, -0.12993580102920532, 4.056039333343506, 2.1231939792633057, -1.9752756357192993, -3.4977991580963135, 2.3547160625457764, -2.538614273071289, -3.1005730628967285, 3.2950124740600586, 1.5786583423614502, 1.029219150543213, 3.8003029823303223, 7.41086483001709, 4.833714962005615, 4.686135292053223, 3.6861190795898438, 1.0704081058502197, -1.153394103050232, 0.1327430158853531, -0.17847135663032532, 2.7929434776306152, 1.3942872285842896, 2.651275157928467, 3.5863635540008545, -1.349609613418579, 0.7771158814430237, 2.1193246841430664, -1.088836908340454, -1.2197763919830322, 2.323293924331665, 1.7822520732879639, -0.7486592531204224, 1.4133548736572266, -1.7270195484161377, 1.162036657333374, -2.896587610244751, 0.3733796179294586, -0.4895496964454651, 1.3639986515045166, -0.5191761255264282, -1.2797611951828003, 0.8893418908119202, -0.266758531332016, 1.1062769889831543, -1.4151866436004639, 0.9914918541908264, -0.38044473528862, -1.570746660232544, -3.336963176727295, -2.2629899978637695, 2.1286418437957764, 1.8622642755508423, 2.431952476501465, 2.3410487174987793, -2.8427212238311768, 0.9984411001205444, 5.951848030090332, 1.1088745594024658, 2.321808338165283, 1.088041067123413, -0.05928251892328262, -1.6388866901397705, 1.0107450485229492, 1.5449658632278442, 0.9218475818634033, 3.4906609058380127, -2.034108877182007, 3.482668876647949, 0.12377338111400604, -0.6332610249519348, 1.5567235946655273, 4.526490688323975, -2.0272507667541504, -0.7406368255615234, 3.708440065383911, 3.604933500289917, -2.201676607131958, -2.769655227661133, 2.6568803787231445, 2.907038688659668, -1.2260148525238037, 1.1031453609466553, 1.1353073120117188, 1.1183967590332031, -1.4834814071655273, -2.810713052749634, 1.6011886596679688, -0.8174840211868286, 2.1779801845550537, 8.382390975952148, 2.6916558742523193, 5.021817207336426, -0.5269366502761841, 5.1312761306762695, 0.35871148109436035, 0.8268856406211853, -3.048966407775879, -1.946885585784912, 1.8050976991653442, 2.6864728927612305, -0.05284437537193298, 1.5757646560668945, 1.5993309020996094, -3.3133182525634766, 1.4187871217727661, 0.703987717628479, -2.3650059700012207, 1.9552587270736694, 2.005549669265747, 0.7686637043952942, 1.7218029499053955, 4.457377910614014, -0.5093288421630859, -3.399513006210327, -0.7936885356903076, 0.6201735138893127, 1.7267661094665527, 1.5922954082489014, 2.089080810546875, 2.2416017055511475, 0.20735937356948853, -0.22250574827194214, -1.1476002931594849, 0.8182787895202637, 3.925121784210205, 2.9439258575439453, 1.6963417530059814, 2.426098108291626, 3.2419517040252686, -0.03562644124031067, 0.013979047536849976, 0.6434848308563232, 1.7725082635879517, 3.926910638809204, 0.06574764847755432, 1.2198114395141602, -1.9581042528152466, 2.0997707843780518, 5.245001316070557, -2.271374464035034, 1.3768891096115112, -2.6039528846740723, 3.0335922241210938, 1.7524082660675049, -0.979320764541626, 0.9700578451156616, 4.8632683753967285, -0.701630711555481, 5.8805975914001465, -0.7093976736068726, 2.251678705215454, 3.9911861419677734, 1.3186960220336914, 1.0896574258804321, -0.4862809479236603, 0.9924403429031372, 0.36557507514953613, 1.7978122234344482, -0.09802035987377167, -2.245889902114868, 0.006884485483169556, 2.0502207279205322, 5.8533453941345215, 5.002739906311035, -0.44378945231437683, 4.358121871948242, 3.0382299423217773, -3.0448639392852783, 1.254040241241455, 0.666394829750061, -1.6996759176254272, 1.4370534420013428, 2.9185986518859863, 0.049933061003685, 0.7433217763900757, 3.2996015548706055, 0.28615230321884155, 2.82873272895813, -1.1645140647888184, 0.6552954912185669, 0.011248260736465454, -2.1171412467956543, 0.01762145757675171, 0.4501764178276062, -0.8552452325820923, 2.017256259918213, 0.1283063292503357, 1.6709821224212646, -0.2449652999639511, 1.6293456554412842, 1.3652366399765015, 0.9794943928718567, 2.2967801094055176, -4.096877098083496, -0.12968260049819946, 0.2179865837097168, -2.987513303756714, 2.9783146381378174, -1.0792609453201294, 1.3408478498458862, -0.3597352206707001, 2.587319850921631, 3.366644859313965, 0.34196043014526367, -0.4815209209918976, 4.75756311416626, 2.5534250736236572, 2.8728301525115967, -1.3751416206359863, -0.6827759742736816, -1.7386798858642578, -2.384470224380493, -1.4554150104522705, -0.5292196869850159, 1.2774850130081177, 3.9571051597595215, 3.1834731101989746, -0.500603437423706, -1.0391508340835571, 1.4513353109359741, 0.3288035988807678, 0.13757207989692688, -0.20545698702335358, 3.432819366455078, 4.058182716369629, 0.17896781861782074, 2.195650815963745, 4.219238758087158, 0.6151485443115234, 2.411207914352417, 2.8581695556640625, 1.4552860260009766, -2.9069998264312744, 0.7010687589645386, 4.047494888305664, 2.283413887023926, -1.6116254329681396, -1.425264596939087, 2.948124408721924, -0.8977971076965332, 1.548349380493164, 0.6755951046943665, -2.02919864654541, -1.199106216430664, -1.5428165197372437, 3.1726508140563965, -0.9971907734870911, 2.2738542556762695, -0.08042655885219574, -0.2851807475090027, -3.3856496810913086, 3.4767448902130127, 0.3303343951702118, -1.6039568185806274, 0.4646710753440857, -1.893594741821289, -0.35931867361068726, 2.2891721725463867, 1.4892865419387817, 0.5862447023391724, 2.0355958938598633, -0.5978798866271973, 1.6684678792953491, -0.40047407150268555, 2.898305892944336, 1.7676478624343872, -0.6766208410263062, 1.7994507551193237, 1.425426959991455, -2.107326030731201, 2.113436460494995, 2.539607048034668, 4.943947792053223, 1.007633924484253, -2.3946735858917236, 1.709291934967041, 1.9733893871307373, 1.815348505973816, 2.025191307067871, -1.8589143753051758, 1.0519038438796997, 4.081240653991699, 0.68267822265625, 0.6751362681388855, 0.9905128479003906, -0.4553433954715729, 2.0130300521850586, -0.9569372534751892, 1.656468391418457, 0.9474085569381714, 0.47571510076522827, -0.29824310541152954, -1.1937731504440308, -3.7774903774261475, -2.024106502532959, 3.599982976913452, -0.0782533586025238, 2.0902676582336426, -1.4428269863128662, 0.47643694281578064, 3.2906575202941895, 1.518465518951416, 1.332567811012268, 0.7467256188392639, 1.0051403045654297, 0.2606908679008484, -0.28368186950683594, -0.9785345196723938, 0.43514204025268555, 1.707087516784668, 1.1008377075195312, -0.8223998546600342, -2.514714002609253, -1.1093251705169678, -0.2971488833427429, 2.415343761444092, -0.4540625512599945, 0.8135235905647278, 1.3090496063232422, 1.3595579862594604, 0.25457942485809326, 2.366690158843994, 0.14589634537696838, -0.7203569412231445, -2.153717041015625, -0.19765636324882507, 2.3053369522094727, 1.780277967453003, 1.9044100046157837, 2.3397669792175293, 3.1424338817596436, 1.7064201831817627, 1.111447811126709, 0.8162039518356323, 1.5998259782791138, 1.653292179107666, -1.3173433542251587, 2.2045576572418213, -0.30105364322662354, 0.7539713382720947, 2.770212411880493, 0.7452671527862549, -0.6804186105728149, 1.761566162109375, 0.35007137060165405, 2.113816738128662, 2.5925188064575195, 2.4160399436950684, 1.8559772968292236, -0.006057381629943848, 2.6411354541778564, -1.8159624338150024, -0.2969910204410553, -1.7617214918136597, -0.49435529112815857, -1.7221956253051758, -1.514782428741455, 0.4312635064125061, -2.6559746265411377, 0.7132059931755066, -1.4388278722763062, -1.1515581607818604, -0.7387489676475525, -1.9944052696228027, 0.6098173260688782, -1.91579270362854, 0.4734521806240082, 2.8897979259490967, -0.3546561598777771, 2.0154170989990234, 1.256115198135376, -0.9053304195404053, -0.7700906991958618, 1.7011417150497437, 2.919983386993408, 2.524158239364624, 0.8116731643676758, -0.23656712472438812, 1.6403343677520752, -0.004307584837079048, 0.04373650997877121, 0.020387720316648483, -0.04788444936275482, 0.09726312756538391, 0.06622970104217529, 0.036455508321523666, -0.042570557445287704, 0.06878077238798141, 0.02305275946855545, 0.0071900468319654465, -0.03159831091761589, 0.0028789136558771133, 0.10692469775676727, -0.04884694144129753, -0.1444186568260193, -0.06880132108926773, 0.027518678456544876, 0.018514301627874374, -0.008997518569231033, -0.050347622483968735, 0.005773313343524933, 0.06788409501314163, 0.007523160427808762, -0.06671663373708725, -0.04767075926065445, -0.015002597123384476, 0.056995123624801636, -0.08898061513900757, 0.07780514657497406, -0.029072487726807594, 0.0485040545463562, -0.10220145434141159, 0.01580839231610298, 0.1095065325498581, 0.03207423537969589, -0.04313477501273155, -0.18217997252941132, -0.08888573199510574, -0.02372588962316513, -0.03036007657647133, 0.036986492574214935, 0.03246047720313072, 0.06842595338821411, 0.111918605864048, -0.030774155631661415, -0.07633939385414124, 0.007332753390073776, 0.01026146113872528, 0.07743843644857407, 0.07807792723178864, 0.013707458041608334, 0.12875871360301971, -0.0032104551792144775, -0.025129586458206177, -0.05180518329143524, 0.05397948622703552, 0.013444945216178894, 0.004782930016517639, -0.027322962880134583, 0.019619114696979523, 0.032203078269958496, -0.031432170420885086, -0.04585152119398117, -0.04077667370438576, 0.08909309655427933, 0.08081677556037903, 0.010303065180778503, 0.08644405007362366, 0.0064824484288692474, 0.16518333554267883, 0.0006083445623517036, 0.05228707194328308, -0.01663641445338726, -0.03881480544805527, -0.03285162150859833, -0.08378006517887115, -0.016935640946030617, 0.08982431888580322, -0.004240725189447403, 0.09138549119234085, -0.020018141716718674, -0.03796060383319855, 0.09444635361433029, -0.009688297286629677, 0.05702692270278931, 0.052256666123867035, 0.04122362285852432, -0.028128473088145256, -0.03273620456457138, -0.011472166515886784, -0.020842481404542923, 0.08036261796951294, 0.09420353919267654, 0.0870823860168457, -0.09783235192298889, -0.018407253548502922, 0.05671137571334839, 0.016149982810020447, 0.07512311637401581, -0.1044122576713562, 0.13246051967144012, -0.014740546233952045, 0.050358451902866364, 0.07462473213672638, -0.0006670914590358734, 0.03727670758962631, -0.09053364396095276, 0.012588456273078918, -0.030338160693645477, -0.010186266154050827, 0.0037912875413894653, 0.017842186614871025, -0.010723743587732315, -0.09168867766857147, 0.0023168884217739105, 0.08349885046482086, 0.13778145611286163, 0.057744622230529785, -0.08151935786008835, 0.03484836965799332, -0.17877955734729767, -0.11378578841686249, 0.05009923130273819, -0.01744360476732254, 0.013881348073482513, -0.03808034956455231, -0.01996748521924019, 0.038696374744176865, -0.02522047609090805, 0.07247860729694366, 0.021208394318819046, 0.09690490365028381, -0.005287611857056618, -0.07509264349937439, -0.09134671092033386, 0.05391494929790497, 0.06106051802635193, -0.11259870231151581, 0.016101479530334473, 0.005208242684602737, 0.04912615567445755, 0.10273636877536774, 0.0759754627943039, -0.055408596992492676, -0.0012718304060399532, 0.060881853103637695, 0.04009895771741867, -0.14490047097206116, 0.0012227408587932587, -0.07872495800256729, 0.09189248085021973, 0.006918556988239288, 0.045848019421100616, -0.04002154991030693, -0.06802569329738617, -0.08014720678329468, -0.051567330956459045, 0.0504859983921051, 0.06769608706235886, 0.15669898688793182, -0.07026982307434082, -0.03583579137921333, 0.06906718015670776, 0.07186552882194519, -0.06335897743701935, 0.019517257809638977, 0.08839955180883408, -0.06888589262962341, -0.06469756364822388, 0.01854124665260315, -0.1263488531112671, 0.13340461254119873, 0.051336511969566345, 0.039668768644332886, -0.14123031497001648, 0.00014092400670051575, 0.03664422035217285, -0.08525650203227997, 0.11312881112098694, -0.01580091193318367, -0.06640173494815826, -0.062102027237415314, 0.03173914551734924, 0.1180325597524643, -0.005183301866054535, -0.13072943687438965, -0.07833418250083923, 0.012197904288768768, -0.16446703672409058, -0.025281457230448723, 0.016714684665203094, 0.05393112450838089, -0.05354834347963333, -0.09841858595609665, -0.06470902264118195, 0.015387509018182755, 0.011187877506017685, 0.0008035972714424133, 0.06095098704099655, -0.012783082202076912, 0.0432865135371685, 0.03074270859360695, -0.017715413123369217, 0.08589199930429459, 0.09867589175701141, -0.014455366879701614, -0.04445405304431915, 0.005160807631909847, 0.07712087035179138, 0.12457108497619629, 0.00877854973077774, 0.027198411524295807, -0.08849452435970306, 0.0032441914081573486, 0.08731779456138611, -0.029923785477876663, -0.07497972249984741, -0.03302982822060585, -0.05873207002878189, -0.019638221710920334, -0.016361458227038383, -0.00018504634499549866, 0.05381777137517929, 0.023358017206192017, 0.017337627708911896, -0.11389540135860443, -0.028336184099316597, 0.07833360135555267, -0.04770267754793167, 0.07456183433532715, 0.07476266473531723, 0.04515998065471649, 0.03661110997200012, -0.028384979814291, -0.11673589795827866, -0.03006828762590885, -0.0033950358629226685, -0.10937250405550003, 0.020410828292369843, -0.016751598566770554, 0.02041541412472725, -0.05206084996461868, 0.05895780026912689, -0.02070268988609314, 0.08041832596063614, 0.012862235307693481, -0.09469299018383026, -0.06894108653068542, -0.015331021510064602, 0.09498204290866852, -0.009554213844239712, -0.08674031496047974, 0.08797885477542877, -0.06050390005111694, 0.0231430996209383, -0.06189645081758499, -0.009972013533115387, 0.003022223711013794, 0.02290855348110199, -0.0056903124786913395, -0.0533578135073185, -0.05422016233205795, -0.002840295433998108, -0.10650750994682312, 0.09485822916030884, 0.06039143353700638, 0.035255543887615204, -0.048915959894657135, -0.044311173260211945, 0.023232657462358475, -0.024257253855466843, 0.024261772632598877, 0.028716273605823517, 0.017347082495689392, 0.19067716598510742, 0.07162703573703766, -0.015273448079824448, 0.04795338958501816, 0.014591339975595474, 0.0009667240083217621, -0.06453900039196014, -0.017446231096982956, -0.03272698447108269, -0.11945384740829468, -0.01443580724298954, 0.09463974833488464, 0.07767453789710999, -0.0005989484488964081, -0.0946182832121849, 0.004096895456314087, 0.07015866786241531, -0.0012806262820959091, -0.12997356057167053, 0.06760912388563156, 0.12109705805778503, 0.024375665932893753, 0.028348863124847412, -0.03060152381658554, -0.038729291409254074, -0.04814236983656883, 0.09209750592708588, -0.08575062453746796, -0.003691993188112974, -0.0989844799041748, 0.07445564866065979, -0.07363325357437134, -0.05849657580256462, 0.06740251928567886, -0.019890297204256058, 0.003613479435443878, -0.04809236526489258, 0.04698985069990158, -0.005902336910367012, 0.07347288727760315, 0.014734352007508278, 0.03142465278506279, -0.02640845999121666, 0.050439924001693726, -0.037437401711940765, -0.09514554589986801, 0.022322669625282288, 0.09823617339134216, -0.06362741440534592, -0.12729397416114807, -0.13341322541236877, -0.018436236307024956, 0.05973111093044281, -0.052984461188316345, 0.07214482128620148, -0.039106786251068115, 0.023253388702869415, -0.001021791249513626, -0.04997996613383293, -0.08239615708589554, -0.03067227639257908, 0.09199345111846924, 0.11721242964267731, 0.044669345021247864, 0.016978397965431213, 0.12007491290569305, -0.12173537909984589, 0.08204984664916992, 0.09403379261493683, -0.04607803001999855, 0.018972285091876984, 0.026199564337730408, 0.04104093834757805, -0.044724591076374054, 0.011941574513912201, -0.10159523785114288, 0.04827194660902023, -0.038836508989334106, -0.03658130392432213, -0.03570838272571564, -0.08016109466552734, -0.1352563500404358, 0.03845144435763359, -0.026930179446935654, 0.018719321116805077, 0.01209576427936554, -0.0058522471226751804, -0.06037053465843201, -0.04218674078583717, -0.07425135374069214, -0.09765540808439255, -0.07426854968070984, 0.041055284440517426, 0.08196581900119781, 0.06763262301683426, 0.029912881553173065, 0.03352469205856323, -0.027315489947795868, 0.05971710383892059, 0.06862043589353561, -0.0728020966053009, 0.04508496820926666, 0.011255751363933086, -0.060847990214824677, 0.01237320527434349, 0.052489764988422394, -0.011348064988851547, 0.013935446739196777, 0.0446065291762352, 0.07906826585531235, 0.006876766681671143, 0.12670458853244781, -0.019363947212696075, -0.033820293843746185, 0.01569424569606781, -0.05136758089065552, 0.07213759422302246, -0.041672877967357635, 0.052306048572063446, 0.06502904742956161, -0.009081326425075531, 0.02316921204328537, -0.021797794848680496, 0.022677766159176826, -0.11610642075538635, -0.12597474455833435, -0.023390168324112892, 0.14830850064754486, 0.014123119413852692, 0.06395293027162552, -0.015109295956790447, 0.07140528410673141, -0.002858305349946022, -0.0030958391726017, -0.06522637605667114, 0.0825871080160141, 0.035731762647628784, 0.03823772072792053, -0.06230311095714569, 0.15132103860378265, -0.08899867534637451, 0.029839783906936646, 0.05765119194984436, 0.055610112845897675, 0.03028695285320282, 0.012953199446201324, -0.05060141906142235, -0.040321603417396545, 0.041161224246025085, -0.08102564513683319, 0.05399671196937561, -0.028943868353962898, 0.04141652584075928, 0.10426303744316101, -0.003466663882136345, -0.03882579505443573, 0.01457338035106659, 0.05401207506656647, 0.0035820547491312027, 0.03079294040799141, 0.08115722984075546, -0.05450401455163956, 0.06234098970890045, 0.04735014587640762, 0.1523369401693344, -0.025298846885561943, 0.005397766828536987, -0.03216494992375374, 0.13601991534233093, 0.010751648806035519, -0.06302443146705627, -0.012964505702257156, -0.04726310074329376, 0.09342082589864731, 0.0614800751209259, 0.04015897959470749, 0.01931816339492798, -0.12948289513587952, -0.05527123808860779, 0.13149206340312958, -0.018827058374881744, -0.0019756779074668884, -0.00593242421746254, 0.10110460221767426, -0.013487935066223145, -0.05667252838611603, -0.07788644731044769, -0.06560562551021576, -0.007260547019541264, 0.05893273651599884, -0.006078530102968216, -0.0066312868148088455, 0.12480425834655762, -0.10182026773691177, 0.08558095991611481, 0.04992535710334778, 0.003264516592025757, 0.0839809775352478, -0.04452652111649513, 0.008454181253910065, 0.016409579664468765, -0.062296271324157715, 0.07036332786083221, -0.08298584818840027, 0.14907854795455933, 0.09271988272666931, -0.05253338813781738, 0.07955494523048401, -0.01397278718650341, 0.051345787942409515, 0.10446856915950775, -0.12912386655807495, -0.09385815262794495, -0.01799289509654045, 0.02072283625602722, -0.080653615295887, 0.06750296801328659, -0.09735983610153198, -0.06614691019058228, 0.022663995623588562, -0.011591672897338867, -0.11453595757484436, 0.09974638372659683, 0.10527917742729187, -0.06539591401815414, -0.032680146396160126, 0.0016477890312671661, 0.06944867968559265, 0.014180295169353485, -0.04816722869873047, -0.0012947190552949905, -0.02424580603837967, -0.007885381579399109, 0.019368011504411697, -0.08945342153310776, -0.009411592036485672, 0.04796986281871796, -0.06868220120668411, -0.05591792240738869, -0.09753750264644623, 0.012367554008960724, -0.03194330260157585, 0.09280769526958466, -0.06478739529848099, 0.026793301105499268, 0.02774690091609955, 0.07112610340118408, -0.04582064971327782, 0.03508245199918747, 0.08131050318479538, 0.028987571597099304, 0.042320579290390015, -0.042067039757966995, -0.04611654207110405, 0.04129563271999359, -0.008118604309856892, -0.04026873782277107, -0.08073706924915314, -0.004099586512893438, 0.0496118888258934, -0.020136084407567978, -0.013936681672930717, 0.09218788146972656, -0.0004054754972457886, -0.004802100360393524, -0.007387734949588776, 0.007832631468772888, 0.03618045523762703, 0.057932980358600616, -0.03218702971935272, 0.004248954355716705, -0.13951706886291504, 0.10948097705841064, -0.06795141100883484, 0.03590608388185501, 0.09247243404388428, 0.00634736567735672, -0.057220831513404846, -0.08301161229610443, -0.19238141179084778, 0.07564829289913177, 0.09756121039390564, 0.08844050765037537, -0.1752004772424698, 0.011399462819099426, -0.04860761761665344, -0.07169701159000397, 0.06402341276407242, 0.027073800563812256, -0.14143508672714233, -0.014533109962940216, -0.003729451447725296, 0.0002869144082069397, 0.04616479575634003, 0.023906756192445755, 0.010523974895477295, 0.0520625114440918, -0.04033474624156952, -0.042537957429885864, 0.0835052877664566, -0.052866026759147644, 0.025300536304712296, 0.0409177765250206, 0.0063525475561618805, 0.052278049290180206, -0.03943721950054169, 0.01628999412059784, -0.004858577623963356, 0.1110418438911438, 0.08392095565795898, -0.03414618968963623, 0.12256920337677002, -0.013711437582969666, -0.014855928719043732, 0.006913397461175919, -0.087366484105587, -0.11710740625858307, -0.0963258370757103, -0.08016860485076904, 0.004869885742664337, -0.04900358244776726, 0.03916950896382332, 0.050424724817276, 0.03472266346216202, -0.035466957837343216, 0.015343144536018372, 0.02861160784959793, -0.04319237172603607, 0.07356878370046616, -0.06582670658826828, -0.08310903608798981, 0.10913623869419098, 0.0297553613781929, 0.07664142549037933, 0.02083444595336914, -0.013117085210978985, -0.029059728607535362, -0.06654523313045502, -0.11724740266799927, -0.10780975222587585, -0.039070338010787964, -0.03342420607805252, 0.03807022050023079, -0.07508252561092377, 0.08121218532323837, -0.05749383568763733, -0.02765871025621891, 0.026522822678089142, 0.13521581888198853, 0.010327480733394623, 0.016688065603375435, 0.04548918455839157, -0.08860154449939728, 0.06205768138170242, -0.20890149474143982, 0.06535129994153976, -31.601215362548828, -0.07607162743806839, -0.04696694761514664, -0.03178486227989197, 0.02946024015545845, -0.049331825226545334, 0.08120796084403992, -0.11486202478408813, 0.05626749247312546, 0.08135905861854553, -0.017401650547981262, -0.10013116151094437, -0.11602558195590973, -0.15197375416755676, -0.022624777629971504, -0.043883148580789566, 0.021763578057289124, 0.03142378851771355, 0.01940058171749115, -0.014901624992489815, -0.04969802871346474, -0.07779188454151154, 0.05183796584606171, 0.05242741107940674, 0.004176657646894455, -0.007844246923923492, -0.007969962432980537, -0.0720946341753006, 0.11765405535697937, -0.06529942154884338, -0.0010068826377391815, -0.14240950345993042, -0.0912015363574028, -0.003763332962989807, 0.07687549293041229, 0.04146304726600647, -0.10415677726268768, -0.032915517687797546, 0.01755935698747635, 0.08193521201610565, -0.08916504681110382, -0.0020306669175624847, 0.16810277104377747, -0.03171978145837784, 0.01562427170574665, 0.023483984172344208, -0.03251828998327255, -0.0932672768831253, -0.007595166563987732, -0.04130923002958298, -0.0056677525863051414, -0.10795692354440689, -0.06918825209140778, -0.08699426054954529, -0.03542180359363556, -0.019484326243400574, 0.07274339348077774, -0.05586990714073181, -0.013829536736011505, -0.04979433864355087, 0.029065094888210297, -0.05369356647133827, 0.11407563090324402, -0.12015882879495621, 0.08229655772447586, -0.1050461158156395, -0.0700165182352066, 0.045218437910079956, -0.05007801949977875, 0.08998953551054001, 0.0037173666059970856, 0.10493366420269012, -0.06733385473489761, 0.11663691699504852, 0.04919234290719032, 0.011368818581104279, 0.07955920696258545, 0.024977825582027435, -0.056587424129247665, 0.06055004149675369, -0.05726142227649689, 0.006358254700899124, -0.08994684368371964, -0.012255478650331497, -0.02079308219254017, 0.040521204471588135, 0.032890792936086655, -0.03337814658880234, -0.03456182777881622, -0.02014976553618908, 0.06923940777778625, -0.17245662212371826, -0.02019973285496235, -0.038385726511478424, 0.022329047322273254, -0.024690372869372368, -0.04439281299710274, 0.007605414837598801, -0.09253808856010437, -0.06699362397193909, -0.06913510710000992, -0.04391413554549217, -0.05130425840616226, 0.06937696039676666, -0.04853781312704086, 0.06797761470079422, -0.05347098037600517, -0.49508023262023926, 0.05899617075920105, -0.09633376449346542, 0.008778940886259079, 0.057795166969299316, 0.05501720309257507, 0.02759019285440445, -0.14488725364208221, -0.014447100460529327, 0.06447417289018631, -0.028334032744169235, -0.021696826443076134, -0.02488732896745205, -0.03189079463481903, -0.005400433205068111, 0.029691196978092194, -0.005963947623968124, -0.010189596563577652, -0.0667666643857956, 0.07060807198286057, -0.15088611841201782, 0.05989828705787659, 0.09279559552669525, -0.15154050290584564, 0.013980820775032043, 0.052053794264793396, -0.03812069445848465, 0.01609097421169281, 0.030930399894714355, -0.018976662307977676, -0.01429811492562294, 0.00575019046664238, -0.14129146933555603, -0.01316651701927185, -0.033895619213581085, 0.04429568722844124, 0.01599084958434105, 0.03542400896549225, 0.15592065453529358, -0.009843512438237667, -0.049706894904375076, 0.055369794368743896, 0.057946689426898956, 0.09652257710695267, -0.05574459210038185, 0.05239773541688919, 0.06294659525156021, 0.001559913158416748, 0.018185250461101532, 0.1256154626607895, -0.028714947402477264, 0.02139587700366974, 0.025796301662921906, 0.03565945848822594, 0.030391763895750046, 0.04768678545951843, 0.0326387993991375, -0.050978921353816986, -0.14456862211227417, 0.08188899606466293, -0.027437085285782814, -0.07049386203289032, 0.04757910221815109, 0.01282428577542305, 0.110719233751297, 0.024068035185337067, 0.0480448454618454, 0.058072447776794434, 0.043906211853027344, 0.01661079376935959, 0.010010134428739548, -0.053518883883953094, 0.044849902391433716, -0.03734521195292473, -0.06345593929290771, -0.003220733255147934, -0.011683346703648567, 0.0375777892768383, -0.05205448716878891, 0.1707356870174408, -0.08492104709148407, -0.0009992104023694992, -0.11241956055164337, -0.0687168538570404, -0.07297807186841965, -0.017823658883571625, 0.13159771263599396, -0.04024890437722206, 0.06034126877784729, -0.0058019571006298065, -0.06533246487379074, -0.018885448575019836, -8.902326226234436e-05, 0.0006214678287506104, 0.06914661824703217, 0.14074480533599854, 0.06937801092863083, 0.0432632714509964, 0.015463002026081085, 0.017448291182518005, 0.13339799642562866, 0.06248738616704941, -0.01337013952434063, -0.17798073589801788, 0.19308556616306305, 0.002826174721121788, 0.03836283087730408, -0.1659485101699829, -0.02699243649840355, -0.06523287296295166, -0.07105063647031784, -0.042101696133613586, -0.06098242104053497, -0.034068234264850616, 0.027239300310611725, 0.08029846847057343, -0.06956314295530319, 0.068067766726017, -0.024377349764108658, -0.024366192519664764, 0.01164974644780159, -0.019719954580068588, 0.03873090445995331, 0.12720052897930145, 0.08664976060390472, -0.01568787358701229, -0.11379870027303696, -0.07055869698524475, -0.03646603971719742, -0.011740874499082565, -0.016696583479642868, -0.011188161559402943, -0.035858117043972015, -0.05418441817164421, -0.0019613616168498993, 0.01493481919169426, 0.038137685507535934, 0.06954434514045715, 0.018968194723129272, 0.041115276515483856, -0.04752007871866226, 0.10223870724439621, -0.00422649085521698, -0.07452379912137985, 0.005090741440653801, -0.04332448169589043, 0.02925485372543335, -0.06828781217336655, -0.03763091191649437, 0.07944683730602264, -0.1454600691795349, -0.017611641436815262, -0.0342119038105011, 0.010770880617201328, 0.08845657855272293, 0.0059501007199287415, -0.0005172817036509514, 0.01896578073501587, -0.09853633493185043, 0.008931150659918785, -3.74913215637207e-05, -0.015819083899259567, 0.09203191101551056, 0.005829658359289169, 0.02511519193649292, -0.09207786619663239, 0.0988999456167221, 0.16535307466983795, 0.03928529471158981, -0.11168079078197479, -0.017622310668230057, 0.17310044169425964, 0.07149966061115265, -0.03213143348693848, -0.02300133928656578, 0.029279492795467377, 0.16310197114944458, -0.04174661263823509, -0.08673419803380966, -0.08182044327259064, -0.024811025708913803, 0.12389758229255676, -0.006651377305388451, 0.007246515713632107, 0.020175520330667496, -0.022315731272101402, 0.05604349821805954, 0.014531904831528664, -0.0016179736703634262, 0.037334784865379333, -0.022399969398975372, 0.04888942092657089, 0.05746162682771683, -0.01902330107986927, -0.020152952522039413, -0.048243023455142975, -0.010219734162092209, -0.011411300860345364, -0.05896800011396408, -0.005241356790065765, 0.04607035964727402, 0.029645398259162903, -0.06721416860818863, -0.011332053691148758, -0.13841864466667175, 0.008344154804944992, -0.07922185957431793, 0.04380866885185242, 0.038035307079553604, 0.03954286128282547, -0.014429604634642601, 0.0117124542593956, 0.08803002536296844, 0.021546650677919388, -0.023427681997418404, 0.04571295529603958, 0.06491399556398392, -0.061276599764823914, -0.014335997402668, 0.037139490246772766, -0.0479709766805172, -0.04534832015633583, 0.07149039953947067, -0.09368269890546799, -0.031556636095047, -0.014698810875415802, -0.04332364350557327, -0.013703882694244385, 0.051403917372226715, -0.026986071839928627, -0.006560548674315214, -0.06648280471563339, -0.019486218690872192, 0.051554933190345764, -0.06379904597997665, -0.43408194184303284, -0.06767049431800842, -0.02032674476504326, -0.07931426167488098, -0.18008454144001007, -0.07188931852579117, -0.10187751054763794, -0.020215408876538277, 0.007032587192952633, 0.07299131155014038, -0.0536733977496624, 0.17811743915081024, 0.0175115168094635, -0.06637845933437347, 0.02237822115421295, -0.09095694124698639, -0.023066453635692596, 0.011888295412063599, 0.006456255912780762, 0.08770407736301422, 0.14413116872310638, 0.11733457446098328, -0.08267708867788315, 0.04880029708147049, -0.06635472178459167, -0.06644777953624725, -0.027737081050872803, -0.10437799245119095, 0.13746653497219086, 0.007019363343715668, 0.09012900292873383, 0.050055019557476044, -0.14134934544563293, 0.02578071504831314, 0.008658617734909058, -0.05691514536738396, -0.027315659448504448, -0.008015505969524384, -0.0248587466776371, 0.05179206281900406, 0.0771770104765892, -0.01562928967177868, 0.030450616031885147, -0.028577305376529694, -0.025888625532388687, 0.0013096146285533905, -0.07758768647909164, 0.05974312871694565, -0.024899734184145927, 0.07148820906877518, 0.06719841063022614]}\n"
     ]
    }
   ],
   "source": [
    "def fuse_features(example):\n",
    "    fused_features = torch.cat((torch.tensor(example['image_features']), torch.tensor(example['question_features'])), dim=0)\n",
    "    return {'fused_features': fused_features.tolist(), 'label': example['label']}\n",
    "\n",
    "# Apply feature fusion to the train and validation datasets\n",
    "train_dataset = train_dataset.map(fuse_features, batched=False)\n",
    "val_dataset = val_dataset.map(fuse_features, batched=False)\n",
    "\n",
    "# Optionally, remove the individual feature columns\n",
    "train_dataset = train_dataset.remove_columns(['image_features', 'question_features'])\n",
    "val_dataset = val_dataset.remove_columns(['image_features', 'question_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define the Model Architecture\n",
    "\n",
    "- Image Feature Input: Use the extracted features from ResNet-50.\n",
    "- Question Feature Input: Use the embeddings from RoBERTa or another text processor.\n",
    "- Fusion Layer: Combine image and question features.\n",
    "- LSTM Layer: Pass the fused features through an LSTM layer for sequence modeling.\n",
    "- Output Layer: Use a dense layer to map the LSTM outputs to the answer classes (classification) or to generate the final answer.\n",
    "2. Loss Function and Optimizer\n",
    "- Loss Function: For classification, use Cross-Entropy Loss since the answers are categorical.\n",
    "- Optimizer: Use Adam optimizer, which is well-suited for training deep learning models due to its adaptive learning rate.\n",
    "- Learning Rate: Set an initial learning rate, e.g., 1e-4, and consider using a learning rate scheduler to reduce the rate as training progresses.\n",
    "3. Training the Model\n",
    "- Batch Size: Select an appropriate batch size, such as 32 or 64, depending on your system's memory.\n",
    "- Epochs: Start with 10-20 epochs and adjust based on the model's performance.\n",
    "- Data Augmentation: If needed, apply techniques like random cropping or flipping to the image data to increase diversity.\n",
    "- Validation Split: Use a portion of the training data for validation (e.g., 10-20%) to monitor the model's performance during training.\n",
    "4. Evaluation Metrics\n",
    "- Accuracy: Calculate the percentage of correct answers.\n",
    "- Precision, Recall, and F1 Score: These metrics are especially important for understanding the model's performance on imbalanced datasets.\n",
    "- Confusion Matrix: Provides insights into specific types of errors the model is making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Prepare DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def prepare_dataloader(dataset, batch_size=32, shuffle=True):\n",
    "    fused_features = torch.tensor(dataset['fused_features'])\n",
    "    labels = torch.tensor(dataset['label'])\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    tensor_dataset = TensorDataset(fused_features, labels)\n",
    "    \n",
    "    # Create a DataLoader\n",
    "    dataloader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "# Prepare DataLoaders for training and validation datasets\n",
    "train_loader = prepare_dataloader(train_dataset)\n",
    "val_loader = prepare_dataloader(val_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VQAModel(nn.Module):\n",
    "    def __init__(self, image_feature_dim, question_feature_dim, hidden_dim, output_dim):\n",
    "        super(VQAModel, self).__init__()\n",
    "        \n",
    "        # Image feature processing\n",
    "        self.image_fc = nn.Linear(image_feature_dim, hidden_dim)\n",
    "        \n",
    "        # Question feature processing\n",
    "        self.question_fc = nn.Linear(question_feature_dim, hidden_dim)\n",
    "        \n",
    "        # LSTM layer for sequence modeling\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, image_features, question_features):\n",
    "        # Process image features\n",
    "        image_features = F.relu(self.image_fc(image_features))\n",
    "        \n",
    "        # Process question features\n",
    "        question_features = F.relu(self.question_fc(question_features))\n",
    "        \n",
    "        # Concatenate image and question features\n",
    "        combined_features = torch.cat((image_features.unsqueeze(1), question_features.unsqueeze(1)), dim=1)\n",
    "        \n",
    "        # Sequence modeling with LSTM\n",
    "        lstm_out, _ = self.lstm(combined_features)\n",
    "        \n",
    "        # Use the output from the last LSTM cell\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Apply dropout\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = self.fc_out(lstm_out)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Parameters for the model\n",
    "image_feature_dim = 2048  # Example: features from ResNet-50\n",
    "question_feature_dim = 768  # Example: embeddings from RoBERTa\n",
    "hidden_dim = 512  # Dimension of the hidden layer in LSTM\n",
    "output_dim = 100  # Number of possible answers (adjust based on your dataset)\n",
    "\n",
    "# Initialize the model\n",
    "model = VQAModel(image_feature_dim, question_feature_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Training and Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column label not in the dataset. Current columns in the dataset: ['image', 'question', 'answer', 'fused_features']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataloader\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Prepare DataLoaders for training and validation datasets\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m prepare_dataloader(val_dataset, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m, in \u001b[0;36mprepare_dataloader\u001b[0;34m(dataset, batch_size, shuffle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_dataloader\u001b[39m(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m     fused_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused_features\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Create a TensorDataset\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     tensor_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(fused_features, labels)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:2658\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2657\u001b[0m     \u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:2642\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2640\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2641\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2642\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2643\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2644\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2645\u001b[0m )\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/datasets/formatting/formatting.py:585\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    583\u001b[0m     _raise_bad_key_type(key)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[43m_check_valid_column_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/datasets/formatting/formatting.py:525\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[0;34m(key, columns)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_valid_column_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, columns: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column label not in the dataset. Current columns in the dataset: ['image', 'question', 'answer', 'fused_features']\""
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for fused_features, labels in train_loader:\n",
    "        fused_features, labels = fused_features.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(fused_features[:, :image_feature_dim], fused_features[:, image_feature_dim:])\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100. * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%')\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for fused_features, labels in val_loader:\n",
    "            fused_features, labels = fused_features.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(fused_features[:, :image_feature_dim], fused_features[:, image_feature_dim:])\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_accuracy = 100. * val_correct / val_total\n",
    "    print(f'Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
