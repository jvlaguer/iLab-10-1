{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2  # Import l2 regularizer\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"flaviagiammarino/vqa-rad\")\n",
    "\n",
    "# Initialize ResNet50 model for image feature extraction\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze all layers except the last 10\n",
    "for layer in resnet_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Initialize RoBERTa-large tokenizer and model\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "roberta_model = TFRobertaModel.from_pretrained('roberta-large')\n",
    "\n",
    "# Function to build vocabulary from the training set questions\n",
    "def build_vocabulary(dataset_split):\n",
    "    vocab = Counter()\n",
    "    for sample in dataset_split:\n",
    "        question = sample['question']\n",
    "        tokens = roberta_tokenizer.tokenize(question)\n",
    "        vocab.update(tokens)\n",
    "    return vocab\n",
    "\n",
    "# Build vocabulary using the training set\n",
    "vocab = build_vocabulary(dataset['train'])\n",
    "print(f\"Vocabulary Size: {len(vocab)}\")\n",
    "\n",
    "# Image preprocessing and augmentation\n",
    "def preprocess_image(img):\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = tf.image.random_flip_left_right(img)  # Augmentation: Flip\n",
    "    img = tf.image.random_brightness(img, 0.2)  # Augmentation: Brightness adjustment\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Feature extraction: image (ResNet50) and text (RoBERTa)\n",
    "def process_image_text(sample):\n",
    "    img = sample['image']\n",
    "    img_array = preprocess_image(img)\n",
    "    \n",
    "    # Extract image features using ResNet50\n",
    "    img_features = resnet_model.predict(img_array)\n",
    "    img_features = img_features.flatten()  # Flatten the image features\n",
    "    \n",
    "    # Tokenize and encode the question using RoBERTa\n",
    "    question = sample['question']\n",
    "    inputs = roberta_tokenizer.encode_plus(question, max_length=512, return_attention_mask=True, return_tensors='tf')\n",
    "    outputs = roberta_model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    text_embeddings = outputs.last_hidden_state[:, 0, :].numpy().flatten()  # Extract the CLS token and flatten\n",
    "    \n",
    "    # Fuse the image features and text embeddings\n",
    "    combined_features = np.concatenate([img_features, text_embeddings])\n",
    "    return combined_features\n",
    "\n",
    "# Process dataset and convert to features\n",
    "def extract_features(dataset_split):\n",
    "    features = []\n",
    "    for sample in dataset_split:\n",
    "        features.append(process_image_text(sample))\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features for train and test datasets\n",
    "train_features = extract_features(dataset['train'])\n",
    "test_features = extract_features(dataset['test'])\n",
    "\n",
    "# Convert labels (\"yes\"/\"no\" to binary)\n",
    "train_labels = np.array([1 if answer == 'yes' else 0 for answer in dataset['train']['answer']])\n",
    "test_labels = np.array([1 if answer == 'yes' else 0 for answer in dataset['test']['answer']])\n",
    "train_labels_cat = to_categorical(train_labels, num_classes=2)\n",
    "test_labels_cat = to_categorical(test_labels, num_classes=2)\n",
    "\n",
    "# Define the VQA classification model using Functional API\n",
    "input_layer = Input(shape=(train_features.shape[1],))  # Adjust the input shape to match the feature vector\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(input_layer)  # Use l2 regularizer\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "output_layer = Dense(2, activation='softmax')(x)  # Binary output (yes/no)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with 20 epochs\n",
    "model.fit(train_features, train_labels_cat, epochs=20, batch_size=32, validation_data=(test_features, test_labels_cat))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_features, test_labels_cat)\n",
    "print(f'Test Loss: {loss:.3f}')\n",
    "print(f'Test Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Predict and display classification report\n",
    "predictions = model.predict(test_features)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification Report:')\n",
    "print(classification_report(test_labels, predicted_classes))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(test_labels, predicted_classes))\n",
    "\n",
    "# Save the model as a Keras model\n",
    "model.save('vqa_model_roberta.keras')\n",
    "\n",
    "print(f'Test Loss: {loss:.3f}')\n",
    "print(f'Test Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('vqa_model_roberta.h5')\n",
    "model.save('vqa_model_roberta.keras')\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model =load_model('vqa_model_roberta.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"flaviagiammarino/vqa-rad\")\n",
    "\n",
    "# Initialize RoBERTa-large tokenizer and model\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "roberta_model = TFRobertaModel.from_pretrained('roberta-large')\n",
    "\n",
    "# Unfreeze all layers in RoBERTa for fine-tuning\n",
    "roberta_model.trainable = True\n",
    "\n",
    "# Initialize ResNet50 model for image feature extraction\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Unfreeze all layers in ResNet50 for fine-tuning\n",
    "resnet_model.trainable = True\n",
    "\n",
    "# Function to preprocess and augment the image\n",
    "def preprocess_image(img):\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = tf.image.random_flip_left_right(img)  # Augmentation: Flip\n",
    "    img = tf.image.random_brightness(img, 0.2)  # Augmentation: Brightness adjustment\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Feature extraction: image (ResNet50) and text (RoBERTa)\n",
    "def process_image_text(sample):\n",
    "    img = sample['image']\n",
    "    img_array = preprocess_image(img)\n",
    "    \n",
    "    # Extract image features using ResNet50\n",
    "    img_features = resnet_model.predict(img_array)\n",
    "    img_features = img_features.flatten()  # Flatten the image features\n",
    "    \n",
    "    # Tokenize and encode the question using RoBERTa\n",
    "    question = sample['question']\n",
    "    inputs = roberta_tokenizer.encode_plus(question, max_length=512, return_attention_mask=True, return_tensors='tf')\n",
    "    outputs = roberta_model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    text_embeddings = outputs.last_hidden_state[:, 0, :].numpy().flatten()  # Extract the CLS token and flatten\n",
    "    \n",
    "    # Fuse the image features and text embeddings\n",
    "    combined_features = np.concatenate([img_features, text_embeddings])\n",
    "    return combined_features\n",
    "\n",
    "# Process dataset and convert to features\n",
    "def extract_features(dataset_split):\n",
    "    features = []\n",
    "    for sample in dataset_split:\n",
    "        features.append(process_image_text(sample))\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features for train and test datasets\n",
    "train_features = extract_features(dataset['train'])\n",
    "test_features = extract_features(dataset['test'])\n",
    "\n",
    "# Convert labels (\"yes\"/\"no\" to binary)\n",
    "train_labels = np.array([1 if answer == 'yes' else 0 for answer in dataset['train']['answer']])\n",
    "test_labels = np.array([1 if answer == 'yes' else 0 for answer in dataset['test']['answer']])\n",
    "train_labels_cat = to_categorical(train_labels, num_classes=2)\n",
    "test_labels_cat = to_categorical(test_labels, num_classes=2)\n",
    "\n",
    "# Define the VQA classification model using Functional API\n",
    "input_layer = Input(shape=(train_features.shape[1],))  # Adjust the input shape to match the feature vector\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(input_layer)\n",
    "x = BatchNormalization()(x)  # Batch normalization for regularization\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "output_layer = Dense(2, activation='softmax')(x)  # Binary output (yes/no)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))  # Convert tensor to float\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "\n",
    "# Train the model with 20 epochs and include learning rate scheduler\n",
    "history = model.fit(train_features, train_labels_cat, epochs=20, batch_size=32, \n",
    "                    validation_data=(test_features, test_labels_cat), \n",
    "                    callbacks=[lr_scheduler])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_features, test_labels_cat)\n",
    "print(f'Test Loss: {loss:.3f}')\n",
    "print(f'Test Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the fine-tuned model as a Keras model\n",
    "model.save('vqa_model_roberta_finetuned.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the VQA classification model using Functional API\n",
    "input_layer = Input(shape=(train_features.shape[1],))\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "output_layer = Dense(2, activation='softmax')(x)  # Binary output (yes/no)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model with a smaller learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with 20 epochs\n",
    "history = model.fit(train_features, train_labels_cat, epochs=20, batch_size=32, \n",
    "                    validation_data=(test_features, test_labels_cat), \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_features, test_labels_cat)\n",
    "print(f'Test Loss: {loss:.3f}')\n",
    "print(f'Test Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Learning Curve - Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Learning Curve - Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow transformers opencv-python datasets\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input  # Corrected import\n",
    "from tensorflow.keras.models import load_model\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the datasets and models\n",
    "dataset = load_dataset(\"flaviagiammarino/vqa-rad\")\n",
    "\n",
    "# Initialize ResNet50 for image feature extraction\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "roberta_model = TFRobertaModel.from_pretrained('roberta-large')\n",
    "\n",
    "# Use your Hugging Face token for authentication\n",
    "token = \" \"\n",
    "\n",
    "# Load the LLAMA 3.1 model and tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(\"openbmb/MiniCPM-Llama3-V-2_5\", use_auth_token=token)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(\"openbmb/MiniCPM-Llama3-V-2_5\", use_auth_token=token)\n",
    "\n",
    "# Load your fine-tuned RoBERTa model\n",
    "roberta_model_finetuned = load_model('/content/drive/My Drive/vqa_model_roberta_finetuned.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to check if an image is a radiology image\n",
    "def is_radiology_image(image_path):\n",
    "    radiology_keywords = ['radiology', 'ct', 'mri', 'xray', 'ultrasound', 'scan', 'image']\n",
    "    file_name = image_path.lower()\n",
    "    \n",
    "    if any(keyword in file_name for keyword in radiology_keywords):\n",
    "        return True\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        return True\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    aspect_ratio = width / height\n",
    "    if aspect_ratio > 1.5:\n",
    "        return True\n",
    "\n",
    "    img_resized = cv2.resize(img, (224, 224))\n",
    "    img_array = np.expand_dims(img_resized, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    predictions = classification_model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    \n",
    "    radiology_classes = {0: 'X-ray', 1: 'CT', 2: 'MRI'}\n",
    "    \n",
    "    if predicted_class_index in radiology_classes:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Function to preprocess and augment the image\n",
    "def preprocess_image(img):\n",
    "    img = cv2.resize(img, (224, 224))  # Resize to match ResNet50 input\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    img = np.expand_dims(img, axis=0)  # Expand dimensions for batch size\n",
    "    return img\n",
    "\n",
    "# Function to process image\n",
    "def process_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if not is_radiology_image(image_path):\n",
    "        return None, \"The uploaded image is not a radiology image. Please upload a valid radiology image.\"\n",
    "\n",
    "    img_array = preprocess_image(img)\n",
    "    img_features = resnet_model.predict(img_array)\n",
    "    img_features = img_features.flatten()\n",
    "    return img, img_features\n",
    "\n",
    "# Function to process question using RoBERTa\n",
    "def process_question(question):\n",
    "    inputs = roberta_tokenizer.encode_plus(question, max_length=512, return_attention_mask=True, return_tensors='tf')\n",
    "    outputs = roberta_model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    text_embeddings = outputs.last_hidden_state[:, 0, :].numpy().flatten()  # Extract the CLS token and flatten\n",
    "    return text_embeddings\n",
    "\n",
    "# Function to handle image and question together\n",
    "def process_image_and_question(image_path, question):\n",
    "    img, img_features = process_image(image_path)\n",
    "    if img is None:\n",
    "        return img_features\n",
    "\n",
    "    text_embeddings = process_question(question)\n",
    "    combined_features = np.concatenate([img_features, text_embeddings])\n",
    "\n",
    "    # Determine if the question is a yes/no type\n",
    "    yes_no_keywords = [\"yes\", \"no\", \"is\", \"are\", \"does\", \"do\", \"should\", \"can\", \"will\"]\n",
    "    if any(keyword in question.lower().split() for keyword in yes_no_keywords):\n",
    "        prediction = roberta_model_finetuned.predict(np.array([combined_features]))\n",
    "        predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "        return \"Yes\" if predicted_class == 1 else \"No\"\n",
    "    else:\n",
    "        # Use LLAMA 3.1 for generating a descriptive answer if the question is not yes/no\n",
    "        generated_text = generate_llama_response(question)\n",
    "        return generated_text\n",
    "\n",
    "# Function to generate a response using LLAMA 3.1\n",
    "def generate_llama_response(question):\n",
    "    inputs = llama_tokenizer(question, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Note: LLAMA expects the input as 'input_ids', not just the raw 'inputs'\n",
    "    input_ids = inputs['input_ids']\n",
    "    outputs = llama_model.generate(input_ids=input_ids, max_length=150)\n",
    "    response = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Function to handle multiple questions in a loop\n",
    "def continuous_question_answer(image_path):\n",
    "    while True:\n",
    "        question = input(\"Enter your question (or type 'exit' to stop): \").strip()\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Session ended.\")\n",
    "            break\n",
    "\n",
    "        # Use the process_image_and_question function to generate answers\n",
    "        result = process_image_and_question(image_path, question)\n",
    "        \n",
    "        if result is None:\n",
    "            print(\"The uploaded image is not a radiology image. Please upload a valid radiology image.\")\n",
    "        else:\n",
    "            print(\"Answer:\", result)\n",
    "\n",
    "# Example usage\n",
    "image_path = '/content/drive/My Drive/image.jpg'\n",
    "continuous_question_answer(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROPBOX LINK\n",
    "\n",
    "https://www.dropbox.com/scl/fo/3qvviu2lqjkjckm9dq881/AGl_McMOsOG8AQ8BJvHxbXA?rlkey=q5l73hxav4tgwzmyl6yn1ka8t&st=une6pds2&dl=0"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
